import os
os.environ["KMP_DUPLICATE_LIB_OK"] = "TRUE"  # OpenMP ì¶©ëŒ ë°©ì§€

import cv2
import numpy as np
import torch
import faiss
import json
from pathlib import Path
from PIL import Image
from ultralytics import YOLO
from transformers import CLIPProcessor, CLIPModel

# âœ… YOLO ëª¨ë¸ ë¡œë“œ
yolo_model = YOLO("yolov8n.pt")  # yolov8n-seg.pt ë„ ê°€ëŠ¥

# âœ… CLIP ëª¨ë¸ ë¡œë“œ
clip_model = CLIPModel.from_pretrained("openai/clip-vit-base-patch32")
clip_processor = CLIPProcessor.from_pretrained("openai/clip-vit-base-patch32")

# âœ… FAISS ì¸ë±ìŠ¤ ë° ë©”íƒ€ë°ì´í„° ë¡œë“œ
index = faiss.read_index("./data/faiss/met_text.index")
with open("./data/faiss/met_structured_with_objects.json", "r", encoding="utf-8") as f:
    image_meta = json.load(f)

# âœ… COCO í´ë˜ìŠ¤ ID â†’ ì´ë¦„ ë§¤í•‘
COCO_CLASSES = yolo_model.model.names

# âœ… ê·¸ë¦¼ ìœ ì‚¬ í´ë˜ìŠ¤ ëª©ë¡ ì •ì˜ (í•„ìš”ì‹œ ìˆ˜ì •)
ART_CLASSES = ["tv", "book", "laptop", "cell phone", "remote", "keyboard", "monitor"]

def embed_crop(image: np.ndarray):
    pil_image = Image.fromarray(image)
    inputs = clip_processor(images=pil_image, return_tensors="pt", padding=True)
    with torch.no_grad():
        embeddings = clip_model.get_image_features(**inputs)
    return embeddings[0].numpy()

# âœ… ì‹¤ì‹œê°„ ì¹´ë©”ë¼ ì²˜ë¦¬ ì‹œì‘
cap = cv2.VideoCapture(0)

while True:
    ret, frame = cap.read()
    if not ret:
        break

    results = yolo_model(frame)[0]

    for box in results.boxes:
        cls_id = int(box.cls[0])
        label = COCO_CLASSES[cls_id]

        # ğŸ” ê·¸ë¦¼ ìœ ì‚¬í•œ í´ë˜ìŠ¤ë§Œ í•„í„°ë§
        if label not in ART_CLASSES:
            continue

        x1, y1, x2, y2 = map(int, box.xyxy[0])
        crop = frame[y1:y2, x1:x2]
        if crop.shape[0] == 0 or crop.shape[1] == 0:
            continue

        query_vec = embed_crop(crop).reshape(1, -1)
        D, I = index.search(query_vec, k=1)

        matched_id = image_meta[I[0][0]]["full_image_id"]
        match_label = f"{label}: {matched_id} ({D[0][0]:.2f})"

        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
        cv2.putText(frame, match_label, (x1, y1 - 10),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 0), 2)

    cv2.imshow("ğŸ¨ Art-Like Detection + FAISS", frame)
    if cv2.waitKey(1) & 0xFF == ord("q"):
        break

cap.release()
cv2.destroyAllWindows()
