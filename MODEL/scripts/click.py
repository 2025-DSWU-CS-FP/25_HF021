import os
import json
import numpy as np
import torch
import cv2
from PIL import Image
from ultralytics import YOLO
from transformers import CLIPProcessor, CLIPModel
from openai import OpenAI
from dotenv import load_dotenv
import requests
import faiss

# â”€â”€ ENV â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "")
BACKEND_OBJECT_DESC_URL = os.getenv("BACKEND_OBJECT_DESC_URL", "http://localhost:8080/api/v1/ai/object-description")
client = OpenAI(api_key=OPENAI_API_KEY)

# â”€â”€ CLIP & FAISS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
device = "cuda" if torch.cuda.is_available() else "cpu"
clip = CLIPModel.from_pretrained("openai/clip-vit-base-patch32").to(device)
processor = CLIPProcessor.from_pretrained("openai/clip-vit-base-patch32")

INDEX_PATH = "data/faiss/met_text.index"
META_PATH  = "data/faiss/met_text_meta.json"  # â† ì—¬ê¸°ì—” objectIDê°€ ìˆì–´ì•¼ í•¨
STRUCTURED_PATH = "data/faiss/met_structured_with_objects.json"  # â† ìƒˆë¡œ ì‚¬ìš©

index = faiss.read_index(INDEX_PATH)
with open(META_PATH, "r", encoding="utf-8") as f:
    faiss_meta = json.load(f)

# â”€â”€ structured JSON ë¡œë“œ & ì¸ë±ì‹±: full_image_id â†’ record â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _load_structured_by_id(path: str):
    with open(path, "r", encoding="utf-8") as f:
        data = json.load(f)
    # ë¦¬ìŠ¤íŠ¸/ë”•ì…”ë„ˆë¦¬ ëª¨ë‘ ëŒ€ì‘
    by_id = {}
    if isinstance(data, dict):
        # ì´ë¯¸ id-keyed ì´ë©´ ê·¸ëŒ€ë¡œ
        if "full_image_id" in data:
            by_id[data["full_image_id"]] = data
        else:
            # nested dictì¼ ìˆ˜ ìˆìœ¼ë‹ˆ ëª¨ë“  value ìŠ¤ìº”
            def _collect(obj):
                if isinstance(obj, dict):
                    if "full_image_id" in obj:
                        by_id[obj["full_image_id"]] = obj
                    else:
                        for v in obj.values():
                            _collect(v)
                elif isinstance(obj, list):
                    for v in obj:
                        _collect(v)
            _collect(data)
    elif isinstance(data, list):
        for item in data:
            if isinstance(item, dict) and "full_image_id" in item:
                by_id[item["full_image_id"]] = item
    return by_id

structured_by_id = _load_structured_by_id(STRUCTURED_PATH)

# â”€â”€ ìœ í‹¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def embed_image(img: Image.Image) -> np.ndarray:
    inputs = processor(images=img, return_tensors="pt").to(device)
    with torch.no_grad():
        emb = clip.get_image_features(**inputs)
        emb = emb / emb.norm(dim=-1, keepdim=True)
    return emb.cpu().numpy().astype("float32").squeeze()

def gpt_docent_ko(description_list, quadrant, painting_name):
    combined = "\n".join(f"- {desc}" for desc in description_list)
    prompt = (
        f"ë‹¹ì‹ ì€ ë¯¸ìˆ ê´€ì˜ ë„ìŠ¨íŠ¸ì…ë‹ˆë‹¤. ì•„ë˜ëŠ” {painting_name}ê·¸ë¦¼ì˜ {quadrant} ë¶„ë©´ì˜ í›„ë³´ ê°ì²´ ì„¤ëª…ì…ë‹ˆë‹¤.\n\n"
        f"{combined}\n\n"
        "â†’ ì´ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ê´€ëŒê°ì—ê²Œ ì¹œì ˆí•˜ê³  ê°ì„±ì ìœ¼ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”. "
        "ë„ˆë¬´ ê¸°ìˆ ì ì´ê±°ë‚˜ ë”±ë”±í•˜ì§€ ì•Šê²Œ í’€ì–´ì£¼ì„¸ìš”."
        "ê·¸ë¦¼ì— ì—†ëŠ” ë‚´ìš©ì€ ì„¤ëª…í•˜ì§€ ë§ˆì„¸ìš”. ê·¸ë¦¼ì— ëŒ€í•œ ë‚´ìš©ë§Œ ì„¤ëª…í•˜ì„¸ìš”."
        "í•´ë‹¹ ê·¸ë¦¼ ì™¸ì˜ ë‹¤ë¥¸ ê·¸ë¦¼ì— ëŒ€í•œ ë‚´ìš©ì€ ì–¸ê¸‰í•˜ì§€ ë§ì•„ì£¼ì„¸ìš”"
        "ê·¸ë¦¼ì— ëŒ€í•œ ì „ì²´ ì„¤ëª…ë³´ë‹¤ëŠ” ê° ê°ì²´ì— ëŒ€í•œ ì„¤ëª…ì„ ì¤‘ì‹¬ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”."
    )
    res = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "user", "content": prompt}]
    )
    return res.choices[0].message.content.strip()

def get_quadrant(x, y, w, h):
    if x < w // 2 and y < h // 2:
        return "Q1"
    elif x >= w // 2 and y < h // 2:
        return "Q2"
    elif x < w // 2 and y >= h // 2:
        return "Q3"
    else:
        return "Q4"

# ê¸°ì¡´ YOLO-ë¶„ë©´ ìœ í‹¸(í•„ìš”ì‹œ ìœ ì§€)
def _intersect_area(a, b):
    ax1, ay1, ax2, ay2 = a
    bx1, by1, bx2, by2 = b
    ix1, iy1 = max(ax1, bx1), max(ay1, by1)
    ix2, iy2 = min(ax2, bx2), min(ay2, by2)
    return max(0, ix2 - ix1) * max(0, iy2 - iy1)

def get_quadrants_for_bbox(x1, y1, x2, y2, w, h, min_ratio=0.05, min_pixels=1):
    x1 = max(0, min(x1, w)); x2 = max(0, min(x2, w))
    y1 = max(0, min(y1, h)); y2 = max(0, min(y2, h))
    if x2 <= x1 or y2 <= y1:
        return [], {}

    mx, my = w // 2, h // 2
    quads = {"Q1": (0,0,mx,my), "Q2": (mx,0,w,my), "Q3": (0,my,mx,h), "Q4": (mx,my,w,h)}
    box = (x1,y1,x2,y2)
    area = (x2-x1)*(y2-y1)
    ratios = {}
    hit = []
    for q, rect in quads.items():
        ia = _intersect_area(box, rect)
        r = (ia/area) if area>0 else 0.0
        ratios[q] = r
        if ia >= min_pixels and r >= min_ratio:
            hit.append(q)
    hit.sort(key=lambda q: ratios[q], reverse=True)
    return hit, ratios

# â”€â”€ ìƒˆë¡œ ì¶”ê°€: structuredì—ì„œ ë¶„ë©´ë³„ crop_description ìˆ˜ì§‘ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def get_crop_descriptions_from_structured(structured_rec: dict, quadrant: str, top_k: int = 5):
    """
    structured_rec["crops"]ì—ì„œ í´ë¦­ ë¶„ë©´(quadrant)ì„ í¬í•¨í•˜ëŠ” cropë§Œ ë½‘ì•„
    quadrant_ratios[quadrant] ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœìœ¼ë¡œ ì •ë ¬í•˜ê³  crop_description ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
    """
    if not structured_rec:
        return []
    crops = structured_rec.get("crops", []) or []
    cand = []
    for c in crops:
        qs = c.get("quadrants", []) or []
        if quadrant in qs:
            ratios = c.get("quadrant_ratios", {}) or {}
            score = float(ratios.get(quadrant, 0.0))
            desc = (c.get("crop_description") or "").strip()
            if desc:
                cand.append((score, desc))
    # ë¶„ë©´ ë¹„ìœ¨ ê¸°ì¤€ ì •ë ¬
    cand.sort(key=lambda x: x[0], reverse=True)
    return [d for _, d in cand[:top_k]]

# â”€â”€ FAISS/ë©”íƒ€ sanity check â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ntotal = index.ntotal
if ntotal == 0:
    print("[ERROR] FAISS index is empty (ntotal=0). ê²€ìƒ‰ ë¶ˆê°€.")
if len(faiss_meta) != ntotal:
    print(f"[WARN] faiss_meta length ({len(faiss_meta)}) != index.ntotal ({ntotal}). ë§¤í•‘ ì–´ê¸‹ë‚¨ ê°€ëŠ¥.")

K = min(3, ntotal)

# â”€â”€ ë©”íƒ€ â†’ structured ë§¤í•‘ í•¨ìˆ˜ (ì´ë¦„ ë¹„êµ ê¸ˆì§€) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def find_structured_record_for_rep(rep_meta: dict) -> dict | None:
    """
    met_text_meta.jsonì˜ rep_metaì—ì„œ objectID(ë˜ëŠ” id, full_image_id)ë¥¼ ì½ì–´
    met_structured_with_objects.jsonì˜ full_image_idë¡œ ë§¤ì¹­í•œë‹¤.
    """
    # ì„ í˜¸: objectID â†’ full_image_id
    rep_id = None
    for key in ("objectID", "full_image_id"):
        if key in rep_meta:
            rep_id = rep_meta[key]
            break
    if rep_id is None:
        print("[WARN] rep_metaì— objectID/full_image_idê°€ ì—†ìŠµë‹ˆë‹¤. (ì´ë¦„ ë§¤ì¹­ì€ ì‚¬ìš©í•˜ì§€ ì•Šë„ë¡ ìš”ì²­ë°›ìŒ)")
        return None
    # int/str í˜¼ìš© ëŒ€ë¹„
    try:
        rep_id_int = int(rep_id)
    except Exception:
        rep_id_int = rep_id  # ê·¸ëŒ€ë¡œ í‚¤ë¡œ ì‹œë„
    rec = structured_by_id.get(rep_id_int) or structured_by_id.get(rep_id)
    if rec is None:
        print(f"[WARN] structured_by_idì—ì„œ full_image_id={rep_id} ë ˆì½”ë“œë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    return rec

# â”€â”€ ë©”ì¸ ë£¨í”„ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def detect_and_search(image_path):
    if not os.path.exists(image_path):
        print(f"â— íŒŒì¼ ì—†ìŒ: {image_path}")
        return

    image_bgr = cv2.imread(image_path)
    h, w = image_bgr.shape[:2]
    image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)
    image_pil = Image.fromarray(image_rgb)

    # YOLO íƒì§€(ì›í•˜ë©´ ìœ ì§€)
    yolo = YOLO("yolov8n-seg.pt")
    results = yolo(image_pil)[0]
    if results.boxes is None or len(results.boxes) == 0:
        print("â— ê°ì²´ê°€ ê°ì§€ë˜ì§€ ì•ŠìŒ")
        return

    # 1) ëŒ€í‘œ ì‘í’ˆ ê²°ì • (CLIPâ†’FAISS)
    whole_emb = embed_image(image_pil).reshape(1, -1)
    distances, indices = index.search(whole_emb, 1)
    rep_idx = int(indices[0][0])
    rep_meta = faiss_meta[rep_idx] if 0 <= rep_idx < len(faiss_meta) else {}
    rep_title  = rep_meta.get("title", "Unknown Artwork")
    rep_artist = rep_meta.get("artist", "Unknown Artist")
    print(f"ğŸ¨ ëŒ€í‘œ ì‘í’ˆ ê²°ì •: {rep_title} by {rep_artist}")

    # 2) structuredì—ì„œ ì´ ëŒ€í‘œì‘ ë ˆì½”ë“œ ì°¾ê¸° (id ë§¤ì¹­)
    structured_rec = find_structured_record_for_rep(rep_meta)

    click_pos = {"x": -1, "y": -1}
    def on_click(event, x, y, flags, param):
        if event == cv2.EVENT_LBUTTONDOWN:
            click_pos["x"], click_pos["y"] = x, y

    cv2.namedWindow("YOLO", cv2.WINDOW_NORMAL)
    cv2.setMouseCallback("YOLO", on_click)

    while True:
        vis = image_bgr.copy()
        cv2.line(vis, (w//2, 0), (w//2, h), (255,255,255), 2)
        cv2.line(vis, (0, h//2), (w, h//2), (255,255,255), 2)
        for box in results.boxes.xyxy.cpu().numpy():
            x1, y1, x2, y2 = map(int, box)
            cv2.rectangle(vis, (x1, y1), (x2, y2), (0, 255, 0), 2)

        cv2.imshow("YOLO", vis)
        key = cv2.waitKey(30) & 0xFF
        if key == ord('q'):
            break

        if click_pos["x"] != -1:
            cx, cy = click_pos["x"], click_pos["y"]
            quadrant = get_quadrant(cx, cy, w, h)
            print(f"âœ… í´ë¦­ëœ ë¶„ë©´: {quadrant}")

            # 3) (ì¤‘ìš”) structuredì—ì„œ ë¶„ë©´ë³„ crop_description ë½‘ê¸°
            desc_list = get_crop_descriptions_from_structured(structured_rec, quadrant, top_k=5)

            # ë§Œì•½ í•´ë‹¹ ë¶„ë©´ cropì´ ì „í˜€ ì—†ë‹¤ë©´, ìµœì†Œí•œ ëŒ€í‘œì‘ ë§¥ë½ì„ ë„£ì–´ì¤€ë‹¤.
            if not desc_list:
                print(f"[INFO] structured ë‚´ë¶€ì— {quadrant} ë¶„ë©´ cropì´ ì—†ìŠµë‹ˆë‹¤. ê°„ë‹¨í•œ ëŒ€ì²´ ì„¤ëª…ìœ¼ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.")
                desc_list = [f"{rep_title}ì˜ {quadrant} ë¶„ë©´ì— ìœ„ì¹˜í•œ ì£¼ìš” ëŒ€ìƒì— ëŒ€í•´ ì„¤ëª…í•´ ì£¼ì„¸ìš”."]

            # 4) GPT ì„¤ëª…
            docent_description = gpt_docent_ko(desc_list, quadrant, rep_title)
            print(rep_title)
            print(f"\n[GPT ì„¤ëª… - {quadrant}]\n{docent_description}\n")

            # 5) ë°±ì—”ë“œ ì „ì†¡
            payload = {
                "quadrant": quadrant,
                "description": docent_description,
                "imageurl": image_path,
                "title": rep_title,
                "artist": rep_artist
            }
            try:
                res = requests.post(BACKEND_OBJECT_DESC_URL, json=payload)
                print(f"[POST] ì „ì†¡ ì™„ë£Œ: {res.status_code} - {res.text}")
            except Exception as e:
                print(f"[ERROR] ë°±ì—”ë“œ ì „ì†¡ ì‹¤íŒ¨: {e}")

            click_pos["x"] = -1

    cv2.destroyAllWindows()

if __name__ == "__main__":
    detect_and_search("data/met_images/image_20003.jpg")
